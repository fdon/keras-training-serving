{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blogpost: training and serving Tensorflow models with tf.Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a high-level interface for neural networks that runs on top of multiple backends. It's functional API is **very user-friendly yet flexible enough** to do lots of cool stuff. Keras quickly gained traction after it's introduction and in 2017, the Keras API was integrated into core Tensorflow as tf.keras. Although tf.keras and Keras have separate code bases, they are tightly coupled and with the updated documentation and programmer guides as of Tensorflow 1.9, tf.keras is clearly the high level API to look for when wiring neural nets on top of Tensorflow. \n",
    "\n",
    "In this blogpost, we will work through the process of training, saving and serving a neural network with tf.keras. As an example, we will train a convolutional neural network on the Kaggle Planet dataset to predict labels for satellite images of the Amazon forest. This is not just a toy dataset, since the goal of the blogpost is to illustrate an end-to-end pipeline for a real-world use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is available for download [here](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data). The training data consists of approximately 40000 labeled images of the Amazon rain forest. Each image is associated with: \n",
    "    * Exactly one out of four possible 'weather' labels: clear, haze, cloudy or partly cloudy\n",
    "    * One or more out of 13 possible 'ground' labels: agriculture, bare_ground, habitation, road, water...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I constructed a Pandas Dataframe with columns for the image names and the weather and ground labels encoded as one-hot binary vectors. The dataframe is available as a .csv file on my githhub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('./KagglePlanetMCML.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to train a model that can accurately predict these labels for new images. We'll try to do this with a network that has two separate outputs for the weather and the ground labels. Predicting the weather labels is an example of a multi-class classification problem, whereas the ground labels can be modelled as a multi-label classification problem. Therefore, the loss function for both outputs will be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a computer vision problem, we will use a convolutional neural network. As it turned out during the Kaggle competition, transfer learning with large pretrained networks was one of the keys to success. This is not the focus here, so we will build our own model from scratch. I'm going for a fairly classical configuration with some convolutional layers and relu activations and won't dwell on anything. For tips on how to achieve a top-of-the-leaderboard performance, check out the great fast.ai lecture that handles this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "IM_SIZE = 16\n",
    "\n",
    "image_input = tf.keras.Input(shape=(IM_SIZE, IM_SIZE, 3), name='input_layer')\n",
    "\n",
    "# Some convolutional layers\n",
    "conv_1 = tf.keras.layers.Conv2D(32,\n",
    "                                kernel_size=(3, 3),\n",
    "                                padding='same',\n",
    "                                activation='relu')(image_input)\n",
    "conv_1 = tf.keras.layers.MaxPooling2D(padding='same')(conv_1)\n",
    "conv_2 = tf.keras.layers.Conv2D(32,\n",
    "                                kernel_size=(3, 3),\n",
    "                                padding='same',\n",
    "                                activation='relu')(conv_1)\n",
    "conv_2 = tf.keras.layers.MaxPooling2D(padding='same')(conv_2)\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "conv_flat = tf.keras.layers.Flatten()(conv_2)\n",
    "\n",
    "# Some dense layers with two separate outputs\n",
    "fc_1 = tf.keras.layers.Dense(128,\n",
    "                             activation='relu')(conv_flat)\n",
    "fc_1 = tf.keras.layers.Dropout(0.2)(fc_1)\n",
    "fc_2 = tf.keras.layers.Dense(128,\n",
    "                             activation='relu')(fc_1)\n",
    "fc_2 = tf.keras.layers.Dropout(0.2)(fc_2)\n",
    "\n",
    "# Output layers: separate outputs for the weather and the ground labels\n",
    "weather_output = tf.keras.layers.Dense(4,\n",
    "                                       activation='softmax',\n",
    "                                       name='weather')(fc_2)\n",
    "ground_output = tf.keras.layers.Dense(13,\n",
    "                                      activation='sigmoid',\n",
    "                                      name='ground')(fc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two output layers, so these should be passed as a list of outputs when specifying the Model. Likewise, we can pass the two separate loss functions as a dictionary (or a list) when compiling the model. Conveniently, the tf.keras Model implementation comes with the extremely handy summary() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        (None, 16, 16, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 32)   896         input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 32)     9248        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 32)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65664       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          16512       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "weather (Dense)                 (None, 4)            516         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ground (Dense)                  (None, 13)           1677        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 94,513\n",
      "Trainable params: 94,513\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=image_input, outputs=[weather_output, ground_output])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon compiling the model, the two different loss functions can be provided as a dictionary that maps tensor names to losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'weather': 'categorical_crossentropy',\n",
    "                    'ground': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model! I will be training this model on my laptop, which does not have enough RAM to take the entire dataset into memory. With image data, this is very often the case. Keras provides the ```fit_generator()``` method that can use a custom Python generator yielding images from disc for training. However, as of Keras 2.0.6, we can use the ```Sequence``` object instead of a generator which allows for safe multiprocessing which means significant speedups and less risk of bottlenecking your GPU if you have one. The Keras documentation already provides good example code, which I will customize a bit to:\n",
    "* make it work with a dataframe that maps image names to labels\n",
    "* shuffle the training data after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from tensorflow.keras.preprocessing.image import img_to_array as img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img as load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, size):\n",
    "    return img_to_array(load_img(image_path, target_size=(size, size))) / 255.\n",
    "\n",
    "class KagglePlanetSequence(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Custom Sequence object to train a model on out-of-memory datasets. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_path, data_path, im_size, batch_size, mode='train'):\n",
    "        \"\"\"\n",
    "        df_path: path to a .csv file that contains columns with image names and labels\n",
    "        data_path: path that contains the training images\n",
    "        im_size: image size\n",
    "        mode: when in training mode, data will be shuffled between epochs\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.im_size = im_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "\n",
    "        # Take labels and a list of image locations in memory\n",
    "        self.wlabels = self.df['weather_labels'].apply(lambda x: ast.literal_eval(x)).tolist()\n",
    "        self.glabels = self.df['ground_labels'].apply(lambda x: ast.literal_eval(x)).tolist()\n",
    "        self.image_list = self.df['image_name'].apply(lambda x: os.path.join(data_path, x + '.jpg')).tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(math.ceil(len(self.df) / self.batch_size)) + 1\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffles indexes after each epoch\n",
    "        self.indexes = range(len(self.image_list))\n",
    "        if self.mode == 'train':\n",
    "            self.indexes = random.sample(self.indexes, k=len(self.indexes))\n",
    "\n",
    "    def get_batch_labels(self, idx): \n",
    "        # Fetch a batch of labels\n",
    "        return [self.wlabels[idx * self.batch_size: (idx + 1) * self.batch_size],\n",
    "                self.glabels[idx * self.batch_size: (idx + 1) * self.batch_size]]\n",
    "\n",
    "    def get_batch_features(self, idx):\n",
    "        # Fetch a batch of images\n",
    "        batch_images = self.image_list[idx * self.batch_size: (1 + idx) * self.batch_size]\n",
    "        return np.array([load_image(im, self.im_size) for im in batch_images])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.get_batch_features(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "BATCH_SIZE = 32\n",
    "seq = KagglePlanetSequence('./KagglePlanetMCML.csv',\n",
    "                       './data/train/',\n",
    "                       im_size=IM_SIZE,\n",
    "                       batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ```Sequence``` object can be used instead of a custom generator together with ```fit_generator()``` to train the model. ```tf.keras``` provides access to all the Keras Callbacks that enhance the training loop. If you evaluate the after each epoch on validation data (which you should do), these can be quite powerful and provide options for early stopping, storing only that version of the model that does not overfit et cetera. Here, we will use the ModelCheckPoint callback just to save the model after every epoch so that we can pick up training afterwards if we want. By default, the model architecture, training configuration, state of the optimizer and the weights are stored, such that the entire model can be recreated from a single file.\n",
    "\n",
    "Let's train the model for 3 epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1264/1265 [============================>.] - ETA: 0s - loss: 0.6260 - weather_loss: 0.4481 - ground_loss: 0.1779\n",
      "Epoch 00001: saving model to ./model.h5\n",
      "1265/1265 [==============================] - 65s 51ms/step - loss: 0.6258 - weather_loss: 0.4479 - ground_loss: 0.1779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3b25b0a50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('./model.h5', verbose=1)\n",
    "]\n",
    "\n",
    "model.fit_generator(generator=seq,\n",
    "                    verbose=1, \n",
    "                    epochs=1,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the Sequence went over all data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265/1265 [==============================] - 123s 97ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40479"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq = KagglePlanetSequence('./KagglePlanetMCML.csv',\n",
    "                       './data/train/',\n",
    "                       im_size=IM_SIZE,\n",
    "                       batch_size=32, mode='test')\n",
    "predictions = model.predict_generator(generator=test_seq, verbose=1)\n",
    "# We get a list of two prediction arrays, for weather and for label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions[1])  == len(df_train) # Total number of images in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we want to finetune the model in a later stage, we can simply read the model file and pick up training even without explicitly recompiling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_model = tf.keras.models.load_model('./model.h5')\n",
    "#another_model.fit_generator(generator=seq, verbose=1, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model, want to export it for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model.signature_def_utils_impl import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "tf.keras.backend.set_learning_phase(0)    \n",
    "model = tf.keras.models.load_model('./model.h5')\n",
    "export_path = './PlanetModel/1'\n",
    "\n",
    "builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "signature = predict_signature_def(inputs={'input_image': model.input},\n",
    "                    outputs={t.name:t for t in model.outputs}) \n",
    "key = tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "\n",
    "with tf.keras.backend.get_session() as sess:\n",
    "    builder.add_meta_graph_and_variables(sess=sess,\n",
    "                                 tags=[tag_constants.SERVING],\n",
    "                                 signature_def_map={key: signature})\n",
    "    \n",
    "    builder.save()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Host and call the model server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A good option is [TensorFlow Serving](https://www.tensorflow.org/serving/):\n",
    "> TensorFlow Serving is a flexible, high-performance serving system for machine learning models, designed for production environments. \n",
    "\n",
    "```Servables``` are the key object in TensorFlow serving. Apart from that, TF Serving provides Loaders and Managers that handle the actual serving, loading of new versions and unloading of old versions.\n",
    "\n",
    "As of TensorFlow serving 1.9, it's possible to make call a hosted model via either gRPC or a REST request. There are quite some tutorials online on how to make gRPC request, we will try doing a REST request here. \n",
    "\n",
    "First of all, I'd like to highlight TensorFlow's `SavedModel` command line tool, which is useful to quickly inspect the input and output specifications of our Model:\n",
    "\n",
    "```\n",
    "$ saved_model_cli show --dir ./ --tag_set serve --signature_def serving_default\n",
    "\n",
    "The given SavedModel SignatureDef contains the following input(s):\n",
    "  inputs['images'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1, 16, 16, 3)\n",
    "      name: input_1_5:0\n",
    "The given SavedModel SignatureDef contains the following output(s):\n",
    "  outputs['ground_5/Sigmoid:0'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1, 13)\n",
    "      name: ground_5/Sigmoid:0\n",
    "  outputs['weather_5/Softmax:0'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1, 4)\n",
    "      name: weather_5/Softmax:0\n",
    "Method name is: tensorflow/serving/predict\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We even have access to ```numpy``` within the CLI (as ```np```) to send some random input to the model to verify that it works:\n",
    "\n",
    "```\n",
    "$ saved_model_cli run --dir ./ --tag_set serve --signature_def serving_default --input_exp 'images=np.random.rand(1,16,16,3)'\n",
    "\n",
    "Result for output key ground_5/Sigmoid:0:\n",
    "[[1.2893094e-01 6.4332830e-04 1.3402618e-03 7.4971933e-04 3.6600672e-05\n",
    "  1.3365776e-04 2.2603733e-02 1.7313704e-02 9.9981135e-01 8.8962197e-02\n",
    "  4.4833246e-04 2.0555612e-04 8.2832985e-02]]\n",
    "Result for output key weather_5/Softmax:0:\n",
    "[[9.3750894e-01 1.9014442e-06 1.9851823e-05 6.2469237e-02]]\n",
    "\n",
    "```\n",
    "\n",
    "Seems to work. Let's host the model from the model directory (some of the output below is truncated for visibility):\n",
    "\n",
    "```\n",
    "$ tensorflow_model_server --model_base_path=$(pwd) --rest_api_port=9000 --model_name=models\n",
    "\n",
    "...\n",
    "I tensorflow_serving/core/basic_manager] Successfully reserved resources to load servable {name: models version: 1}\n",
    "I tensorflow_serving/core/loader_harness] Approving load for servable version {name: models version: 1}\n",
    "I tensorflow_serving/core/loader_harness] Loading servable version {name: models version: 1}\n",
    "I external/org_tensorflow/tensorflow/cc/saved_model/loader] SavedModel load for tags { serve }; Status: success. Took 883423 microseconds.\n",
    "I tensorflow_serving/core/loader_harness] Successfully loaded servable version {name: models version: 1}\n",
    "...\n",
    "I tensorflow_serving/model_servers/main] Exporting HTTP/REST API at:localhost:9000 ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can send requests to our server via the python `request` module:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "image = img_to_array(load_img('./data/train/train_10001.jpg', target_size=(128,128))) / 255.\n",
    "payload = {\n",
    "  \"instances\": [{'input_image': image.tolist()}]\n",
    "}\n",
    "r = requests.post('http://localhost:9000/v1/models/PlanetModel:predict', json=payload)\n",
    "json.loads(r.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (blogpost)",
   "language": "python",
   "name": "blogpost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
