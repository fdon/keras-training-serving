{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blogpost: training and serving Tensorflow models with tf.Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a high-level interface for neural networks that runs on top of multiple backends. It's functional API is **very user-friendly yet flexible enough** to do lots of cool stuff. Keras quickly gained traction after it's introduction and in 2017, the Keras API was integrated into core Tensorflow as tf.keras. Although tf.keras and Keras have separate code bases, they are tightly coupled and with the updated documentation and programmer guides as of Tensorflow 1.9, tf.keras is clearly the high level API to look for when wiring neural nets on top of Tensorflow. \n",
    "\n",
    "In this blogpost, we will work through the process of training, saving and serving a neural network with tf.keras. As an example, we will train a convolutional neural network on the Kaggle Planet dataset to predict labels for satellite images of the Amazon forest. This is not just a toy dataset, since the goal of the blogpost is to illustrate an end-to-end pipeline for a real-world use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is available for download [here](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data). The training data consists of approximately 40000 labeled images of the Amazon rain forest. Each image is associated with: \n",
    "    * Exactly one out of four possible 'weather' labels: clear, haze, cloudy or partly cloudy\n",
    "    * One or more out of 13 possible 'ground' labels: agriculture, bare_ground, habitation, road, water...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I constructed a Pandas Dataframe with columns for the image names and the weather and ground labels encoded as one-hot binary vectors. The dataframe is available as a .csv file on my githhub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('./KagglePlanetMCML.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to train a model that can accurately predict these labels for new images. We'll try to do this with a network that has two separate outputs for the weather and the ground labels. Predicting the weather labels is an example of a multi-class classification problem, whereas the ground labels can be modelled as a multi-label classification problem. Therefore, the loss function for both outputs will be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a computer vision problem, we will use a convolutional neural network. As it turned out during the Kaggle competition, transfer learning with large pretrained networks was one of the keys to success. This is not the focus here, so we will build our own model from scratch. I'm going for a fairly classical configuration with some convolutional layers and relu activations and won't dwell on anything. For tips on how to achieve a top-of-the-leaderboard performance, check out the great fast.ai lecture that handles this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/h5py/__init__.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/h5py/__init__.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import h5a, h5d, h5ds, h5f, h5fd, h5g, h5r, h5s, h5t, h5p, h5z\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/h5py/_hl/group.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .. import h5g, h5i, h5o, h5r, h5t, h5l, h5p\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/linalg/__init__.py:207: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ufuncs import *\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/interpolate/_bsplines.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _bspl\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/spatial/__init__.py:96: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/spatial/distance.py:122: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/home/stijn/venvs/blogpost/local/lib/python2.7/site-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _ni_label\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "IM_SIZE = 16\n",
    "\n",
    "image_input = tf.keras.Input(shape=(IM_SIZE, IM_SIZE, 3), name='input_layer')\n",
    "\n",
    "# Some convolutional layers\n",
    "conv_1 = tf.keras.layers.Conv2D(32,\n",
    "                                kernel_size=(3, 3),\n",
    "                                padding='same',\n",
    "                                activation='relu')(image_input)\n",
    "conv_1 = tf.keras.layers.MaxPooling2D(padding='same')(conv_1)\n",
    "conv_2 = tf.keras.layers.Conv2D(32,\n",
    "                                kernel_size=(3, 3),\n",
    "                                padding='same',\n",
    "                                activation='relu')(conv_1)\n",
    "conv_2 = tf.keras.layers.MaxPooling2D(padding='same')(conv_2)\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "conv_flat = tf.keras.layers.Flatten()(conv_2)\n",
    "\n",
    "# Some dense layers with two separate outputs\n",
    "fc_1 = tf.keras.layers.Dense(128,\n",
    "                             activation='relu')(conv_flat)\n",
    "fc_1 = tf.keras.layers.Dropout(0.2)(fc_1)\n",
    "fc_2 = tf.keras.layers.Dense(128,\n",
    "                             activation='relu')(fc_1)\n",
    "fc_2 = tf.keras.layers.Dropout(0.2)(fc_2)\n",
    "\n",
    "# Output layers: separate outputs for the weather and the ground labels\n",
    "weather_output = tf.keras.layers.Dense(4,\n",
    "                                       activation='softmax',\n",
    "                                       name='weather')(fc_2)\n",
    "ground_output = tf.keras.layers.Dense(13,\n",
    "                                      activation='sigmoid',\n",
    "                                      name='ground')(fc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two output layers, so these should be passed as a list of outputs when specifying the Model. Likewise, we can pass the two separate loss functions as a dictionary (or a list) when compiling the model. Conveniently, the tf.keras Model implementation comes with the extremely handy summary() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        (None, 16, 16, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 16, 16, 32)   896         input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 8, 8, 32)     0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 8, 32)     9248        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 32)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          65664       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "weather (Dense)                 (None, 4)            516         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ground (Dense)                  (None, 13)           1677        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 94,513\n",
      "Trainable params: 94,513\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=image_input, outputs=[weather_output, ground_output])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon compiling the model, the two different loss functions can be provided as a dictionary that maps tensor names to losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'weather': 'categorical_crossentropy',\n",
    "                    'ground': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model! I will be training this model on my laptop, which does not have enough RAM to take the entire dataset into memory. With image data, this is very often the case. Keras provides the ```fit_generator()``` method that can use a custom Python generator yielding images from disc for training. However, as of Keras 2.0.6, we can use the ```Sequence``` object instead of a generator which allows for safe multiprocessing which means significant speedups and less risk of bottlenecking your GPU if you have one. The Keras documentation already provides good example code, which I will customize a bit to:\n",
    "* make it work with a dataframe that maps image names to labels\n",
    "* shuffle the training data after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from tensorflow.keras.preprocessing.image import img_to_array as img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img as load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, size):\n",
    "    return img_to_array(load_img(image_path, target_size=(size, size))) / 255.\n",
    "\n",
    "class KagglePlanetSequence(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Custom Sequence object to train a model on out-of-memory datasets. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_path, data_path, im_size, batch_size, mode='train'):\n",
    "        \"\"\"\n",
    "        df_path: path to a .csv file that contains columns with image names and labels\n",
    "        data_path: path that contains the training images\n",
    "        im_size: image size\n",
    "        mode: when in training mode, data will be shuffled between epochs\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(df_path)\n",
    "\n",
    "        # Take labels and a list of image locations in memory\n",
    "        self.wlabels = self.df['weather_labels'].apply(lambda x: ast.literal_eval(x)).tolist()\n",
    "        self.glabels = self.df['ground_labels'].apply(lambda x: ast.literal_eval(x)).tolist()\n",
    "        self.image_list = self.df['image_name'].apply(lambda x: os.path.join(data_path, x + '.jpg')).tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(math.ceil(len(self.df) / float(batch_size)))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffles indexes after each epoch\n",
    "        self.indexes = range(len(self.image_list))\n",
    "        if mode == 'train':\n",
    "            self.indexes = random.sample(self.indexes, k=len(self.indexes))\n",
    "\n",
    "    def get_batch_labels(self, idx): \n",
    "        # Fetch a batch of labels\n",
    "        return [self.wlabels[idx * batch_size: (idx + 1) * batch_size],\n",
    "                self.glabels[idx * batch_size: (idx + 1) * batch_size]]\n",
    "\n",
    "    def get_batch_features(self, idx):\n",
    "        # Fetch a batch of images\n",
    "        batch_images = self.image_list[idx * batch_size: (1 + idx) * batch_size]\n",
    "        return np.array([load_image(im, im_size) for im in batch_images])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.get_batch_features(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "BATCH_SIZE = 32\n",
    "seq = KagglePlanetSequence('./KagglePlanetMCML.csv',\n",
    "                       './data/train/',\n",
    "                       im_size=IM_SIZE,\n",
    "                       batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ```Sequence``` object can be used instead of a custom generator together with ```fit_generator()``` to train the model. ```tf.keras``` provides access to all the Keras Callbacks that enhance the training loop. If you evaluate the after each epoch on validation data (which you should do), these can be quite powerful and provide options for early stopping, storing only that version of the model that does not overfit et cetera. Here, we will use the ModelCheckPoint callback just to save the model after every epoch so that we can pick up training afterwards if we want. By default, the model architecture, training configuration, state of the optimizer and the weights are stored, such that the entire model can be recreated from a single file.\n",
    "\n",
    "Let's train the model for 3 epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1262/1265 [============================>.] - ETA: 0s - loss: 0.6606 - weather_loss: 0.4793 - ground_loss: 0.1813\n",
      "Epoch 00001: saving model to ./model.h5\n",
      "1265/1265 [==============================] - 66s 52ms/step - loss: 0.6604 - weather_loss: 0.4792 - ground_loss: 0.1812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa69f42b990>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('./model.h5', verbose=1)\n",
    "]\n",
    "\n",
    "model.fit_generator(generator=seq,\n",
    "                    verbose=1, \n",
    "                    epochs=1,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the Sequence went over all data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265/1265 [==============================] - 122s 97ms/step\n"
     ]
    }
   ],
   "source": [
    "test_seq = KagglePlanetSequence('./KagglePlanetMCML.csv',\n",
    "                       './data/train/',\n",
    "                       im_size=IM_SIZE,\n",
    "                       batch_size=32, mode='test')\n",
    "predictions = model.predict_generator(generator=test_seq, verbose=1)\n",
    "# We get a list of two prediction arrays, for weather and for label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions[1])  == len(df_train) # Total number of images in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we want to finetune the model in a later stage, we can simply read the model file and pick up training even without explicitly recompiling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_model = tf.keras.models.load_model('./model.h5')\n",
    "#another_model.fit_generator(generator=seq, verbose=1, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model, want to export it for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model.signature_def_utils_impl import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "tf.keras.backend.set_learning_phase(0)    \n",
    "model = tf.keras.models.load_model('./model.h5')\n",
    "export_path = './PlanetModel/1'\n",
    "\n",
    "builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "signature = predict_signature_def(inputs={'input_image': model.input},\n",
    "                    outputs={t.name:t for t in model.outputs}) \n",
    "key = tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "\n",
    "with tf.keras.backend.get_session() as sess:\n",
    "    builder.add_meta_graph_and_variables(sess=sess,\n",
    "                                 tags=[tag_constants.SERVING],\n",
    "                                 signature_def_map={key: signature})\n",
    "    \n",
    "    builder.save()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Host and call the model server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A good option is [TensorFlow Serving](https://www.tensorflow.org/serving/):\n",
    "> TensorFlow Serving is a flexible, high-performance serving system for machine learning models, designed for production environments. \n",
    "\n",
    "```Servables``` are the key object in TensorFlow serving. Apart from that, TF Serving provides Loaders and Managers that handle the actual serving, loading of new versions and unloading of old versions.\n",
    "\n",
    "As of TensorFlow serving 1.9, it's possible to make call a hosted model via either gRPC or a REST request. There are quite some tutorials online on how to make gRPC request, we will try doing a REST request here. \n",
    "\n",
    "First of all, I'd like to highlight TensorFlow's `SavedModel` command line tool, which is useful to quickly inspect the input and output specifications of our Model:\n",
    "\n",
    "```\n",
    "$ saved_model_cli show --dir ./ --tag_set serve --signature_def serving_default\n",
    "\n",
    "The given SavedModel SignatureDef contains the following input(s):\n",
    "  inputs['images'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1, 16, 16, 3)\n",
    "      name: input_1_5:0\n",
    "The given SavedModel SignatureDef contains the following output(s):\n",
    "  outputs['ground_5/Sigmoid:0'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1, 13)\n",
    "      name: ground_5/Sigmoid:0\n",
    "  outputs['weather_5/Softmax:0'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1, 4)\n",
    "      name: weather_5/Softmax:0\n",
    "Method name is: tensorflow/serving/predict\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We even have access to ```numpy``` within the CLI (as ```np```) to send some random input to the model to verify that it works:\n",
    "\n",
    "```\n",
    "$ saved_model_cli run --dir ./ --tag_set serve --signature_def serving_default --input_exp 'images=np.random.rand(1,16,16,3)'\n",
    "\n",
    "Result for output key ground_5/Sigmoid:0:\n",
    "[[1.2893094e-01 6.4332830e-04 1.3402618e-03 7.4971933e-04 3.6600672e-05\n",
    "  1.3365776e-04 2.2603733e-02 1.7313704e-02 9.9981135e-01 8.8962197e-02\n",
    "  4.4833246e-04 2.0555612e-04 8.2832985e-02]]\n",
    "Result for output key weather_5/Softmax:0:\n",
    "[[9.3750894e-01 1.9014442e-06 1.9851823e-05 6.2469237e-02]]\n",
    "\n",
    "```\n",
    "\n",
    "Seems to work. Let's host the model from the model directory (some of the output below is truncated for visibility):\n",
    "\n",
    "```\n",
    "$ tensorflow_model_server --model_base_path=$(pwd) --rest_api_port=9000 --model_name=models\n",
    "\n",
    "...\n",
    "I tensorflow_serving/core/basic_manager] Successfully reserved resources to load servable {name: models version: 1}\n",
    "I tensorflow_serving/core/loader_harness] Approving load for servable version {name: models version: 1}\n",
    "I tensorflow_serving/core/loader_harness] Loading servable version {name: models version: 1}\n",
    "I external/org_tensorflow/tensorflow/cc/saved_model/loader] SavedModel load for tags { serve }; Status: success. Took 883423 microseconds.\n",
    "I tensorflow_serving/core/loader_harness] Successfully loaded servable version {name: models version: 1}\n",
    "...\n",
    "I tensorflow_serving/model_servers/main] Exporting HTTP/REST API at:localhost:9000 ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can send requests to our server via the python `request` module:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "image = img_to_array(load_img('./data/train/train_10001.jpg', target_size=(128,128))) / 255.\n",
    "payload = {\n",
    "  \"instances\": [{'input_image': image.tolist()}]\n",
    "}\n",
    "r = requests.post('http://localhost:9000/v1/models/PlanetModel:predict', json=payload)\n",
    "json.loads(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Dataset api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TFRecordWriter.close of <tensorflow.python.lib.io.tf_record.TFRecordWriter object at 0x7fa86da48510>>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize images, together with labels, to TF records\n",
    "IM_SIZE = 128\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "tf_records_filename = './data/KagglePlanetTFRecord_{}'.format(IM_SIZE)\n",
    "writer = tf.python_io.TFRecordWriter(tf_records_filename)\n",
    "\n",
    "# List of image paths, np array of labels\n",
    "im_list = [os.path.join('./data/train', v + '.jpg') for v in df_train['image_name'].tolist()]\n",
    "w_labels_arr = np.array([ast.literal_eval(l) for l in df_train['weather_labels']])\n",
    "g_labels_arr = np.array([ast.literal_eval(l) for l in df_train['ground_labels']])\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    w_labels = w_labels_arr[i].astype(np.float32)\n",
    "    g_labels = g_labels_arr[i].astype(np.float32)\n",
    "    im = np.array(img_to_array(load_img(im_list[i], target_size=(IM_SIZE, IM_SIZE))) / 255.)\n",
    "    w_raw = w_labels.tostring()\n",
    "    g_raw = g_labels.tostring()\n",
    "    im_raw = im.tostring()\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature={'image': _bytes_feature(im_raw),\n",
    "                                                                  'weather_labels': _bytes_feature(w_raw),\n",
    "                                                                  'ground_labels': _bytes_feature(g_raw)}))\n",
    "    \n",
    "    writer.write(example.SerializeToString())\n",
    "    \n",
    "writer.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import FixedLenFeature\n",
    "featdef = {\n",
    "           'image': FixedLenFeature(shape=[], dtype=tf.string),\n",
    "           'weather_labels': FixedLenFeature(shape=[], dtype=tf.string),\n",
    "           'ground_labels': FixedLenFeature(shape=[], dtype=tf.string)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_record(example_proto, clip=False):\n",
    "    ex = tf.parse_single_example(example_proto, featdef)\n",
    "    \n",
    "    im = tf.decode_raw(ex['image'], tf.float32)\n",
    "    im = tf.reshape(im, (IM_SIZE, IM_SIZE, 3))\n",
    "    weather = tf.decode_raw(ex['weather_labels'], tf.float32)\n",
    "    ground = tf.decode_raw(ex['ground_labels'], tf.float32)\n",
    "    return im, weather, ground\n",
    "\n",
    "# Construct a dataset iterator\n",
    "batch_size = 32\n",
    "ds_train = tf.data.TFRecordDataset('./data/KagglePlanetTFRecord_{}'.format(IM_SIZE)).map(_parse_record).batch(batch_size)\n",
    "iterator = tf.data.Iterator.from_structure(ds_train.output_types, ds_train.output_shapes)\n",
    "\n",
    "ds_tr_init = iterator.make_initializer(ds_train)\n",
    "\n",
    "x,w,g = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1264/1264 [==============================] - 743s 587ms/step - loss: 0.4780 - weather_loss: 0.2830 - ground_loss: 0.1950\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    tf.keras.backend.set_session(sess)\n",
    "    sess.run(ds_tr_init) # initialize the generator\n",
    "  \n",
    "    # Rewire network to tie it into the generator\n",
    "    image_input = tf.keras.Input(tensor=x)\n",
    "\n",
    "    # Model definition\n",
    "    ...\n",
    "\n",
    "    # Output layers: separate outputs for the weather and the ground labels\n",
    "    weather_output = tf.keras.layers.Dense(4,\n",
    "                                           activation='softmax',\n",
    "                                           name='weather')(fc_2)\n",
    "    ground_output = tf.keras.layers.Dense(13,\n",
    "                                          activation='sigmoid',\n",
    "                                          name='ground')(fc_2)\n",
    "\n",
    "    \n",
    "    steps_per_epoch = len(df_train) // batch_size\n",
    "    # Specify the model\n",
    "    model = tf.keras.Model(inputs=image_input, outputs=[weather_output, ground_output])\n",
    "    \n",
    "    # Supply the outputs of the generator as target tensors\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', target_tensors=[w,g])\n",
    "\n",
    "    model.fit(steps_per_epoch=steps_per_epoch, verbose=1, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (blogpost)",
   "language": "python",
   "name": "blogpost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
